{
    "RuntimeError: 0INTERNAL ASSERT FAILED": "PyTorch JiT trace error",
    "onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument": "Wrong tokenizer type in the repository. To convert the model you could create a repository with the same model and right tokenizer type and use it instead.",
    "Connection error, and we cannot find the requested files in the cached path": "Connection error. Check the internet connection.",
    "TypeError: not a string": "Cannot initialize tokenizer from the repository.",
    "Error(s) in loading state_dict": "Cannot initialize the the model from the repository. Try to connect the repository creator of the repository.",
    "sequence item 0: expected str instance": "[unk] and [pad] tokens for tokenizer are not set.",
    "expected str, bytes or os.PathLike object": "Not enough files for tokenizer initialization in the repository",
    "path should be string, bytes, os.PathLike or integer": "Not enough files for tokenizer initialization in the repository",
    "The state dictionary of the model you are training to load is corrupted": "Cannot initialize the model form the repository. It may not have been saved properly.",
    "No such file or directory (os error 2)": "Cannot initialize tokenizer from the repository.",
    "Can't load tokenizer for": "Cannot initialize tokenizer from the repository.",
    "Exporting model exceed maximum protobuf size of 2GB": "Cannot convert a large model to ONNX.",
    "Connection error": "Connection error, check the internet connection.",
    "Model and config inputs doesn't match": "Cannot convert model to ONNX - model and config inputs doesn't match. The repository might contain wrong tokenizer type.",
    "Wrong index found for [MASK]": "Cannot initialize tokenizer from the model repository.",
    "JSONDecodeError": "Cannot initialize tokenizer from the model repository - the json file is corrupted."
}
