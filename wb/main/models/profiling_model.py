"""
 OpenVINO DL Workbench
 Class for ORM model described an Infer Job

 Copyright (c) 2018 Intel Corporation

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
      http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
"""
from pathlib import Path
from typing import List, Optional

from sqlalchemy import Column, Integer, ForeignKey, DateTime, Boolean

from config.constants import PROFILING_ARTIFACTS_REPORT_DIR, JOBS_SCRIPTS_FOLDER_NAME, \
    PROFILING_BINARY_DATASET_FOLDER, PROFILING_CONFIGURATION_FILE_NAME, JOB_SCRIPT_NAME
from wb.main.enumerates import JobTypesEnum, StatusEnum, ModelDomainEnum
from wb.main.models import DatasetsModel
from wb.main.models.jobs_model import JobsModel
from wb.main.utils.utils import find_by_ext


class ProfilingJobModel(JobsModel):
    __tablename__ = 'profiling_jobs'

    __mapper_args__ = {
        'polymorphic_identity': JobTypesEnum.profiling_type.value
    }

    job_id = Column(Integer, ForeignKey(JobsModel.job_id), primary_key=True)

    inference_time = Column(Integer, nullable=False)
    num_single_inferences = Column(Integer, nullable=False)

    started_timestamp = Column(DateTime, nullable=True)

    autogenerated = Column(Boolean, default=False)

    # Annotations
    profiling_results: Optional[List['SingleInferenceInfoModel']]

    def __init__(self, data):
        super().__init__(data)
        self.inference_time = data['inferenceTime']
        self.num_single_inferences = data['numSingleInferences']
        self.progress = 0
        self.autogenerated = False

    def profiling_results_json(self):
        return [r.short_json() for r in self.profiling_results]

    @property
    def xml_model_path(self) -> str:
        return find_by_ext(self.project.topology.path, 'xml')

    @property
    def next_jobs(self) -> List['JobsModel']:
        profiling_results = self.profiling_results
        queued_profiling_results = [j for j in profiling_results if j.status == StatusEnum.queued]
        return [*queued_profiling_results, *super().next_jobs]

    def set_data_generation_method(self) -> None:
        self.autogenerated = self.project.topology.tokenizer_model is None

    @property
    def input_data_path(self) -> Optional[str]:
        dataset: DatasetsModel = self.project.dataset
        if self.autogenerated and self.project.topology.domain is ModelDomainEnum.NLP:
            return None
        if self.autogenerated:
            return dataset.dataset_data_dir
        # Return binary data generated for profiling
        return str(self.binary_dataset_directory_path)

    @property
    def input_data_base_dir_path(self) -> str:
        dataset: DatasetsModel = self.project.dataset
        if self.autogenerated:
            return dataset.path
        return str(self.binary_dataset_directory_path)

    # TODO 77386 Consider changing to method with optional argument for remote use case (default for local)
    @property
    def profiling_artifacts_path(self) -> Path:
        return Path(PROFILING_ARTIFACTS_REPORT_DIR) / str(self.pipeline_id)

    @property
    def profiling_scripts_dir_path(self) -> Path:
        return self.profiling_artifacts_path / JOBS_SCRIPTS_FOLDER_NAME

    @property
    def profiling_job_script_path(self) -> Path:
        return self.profiling_scripts_dir_path / JOB_SCRIPT_NAME

    @property
    def binary_dataset_directory_path(self) -> Path:
        return self.profiling_artifacts_path / PROFILING_BINARY_DATASET_FOLDER

    @property
    def configuration_file_path(self) -> Path:
        return self.profiling_scripts_dir_path / PROFILING_CONFIGURATION_FILE_NAME

    def json(self) -> dict:
        return {
            'jobId': self.job_id,
            'projectId': self.project_id,
            'originalModelId': self.project.get_top_level_model_id(),
            'type': self.get_polymorphic_job_type(),
            'deviceType': self.project.device.type,
            'inferenceTime': self.inference_time,
            'inferences': self.profiling_results_json(),
            'created': self.timestamp_to_milliseconds(self.creation_timestamp),
            'started': self.timestamp_to_milliseconds(self.started_timestamp) if self.started_timestamp else None,
            'updated': self.timestamp_to_milliseconds(self.last_modified),
            'status': self.status_to_json(),
            'autogenerated': self.autogenerated,
        }
